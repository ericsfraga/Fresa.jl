#+INCLUDE:   /home/ucecesf/hg/homepages/level-0.org
#+title: Fresa, a plant propagation algorithm
#+options: num:nil ^:nil toc:nil tex:imagemagick

| *Author*        | {{{author}}} ({{{email}}})                   |
| *Last revision* | {{{modification-time(%Y-%m-%d %H:%M:%S,t)}}} |

#+toc: headlines 1

* TODO bugs and new features [2/6]                            :noexport:
- [ ] consider splicing out the selected member from the population
- [ ] parallelise the evaluation of the new members of the population
- [ ] add counters to be able to display number of function evaluations etc.
- [ ] use constraint information in fitness calculations
- [X] allow for user specified /neighbour/ function
- [X] implement MINLP example
* Overview and introduction
/Fresa/ is an implementation of a /plant propagation algorithm/ in [[http://www.julialang.org/][Julia]] programming language.  Our original version was called [[file:strawberry.org][Strawberry]], written in Octave (and usable in MATLAB).  Please see the [[file:strawberry.org][documentation]] of Strawberry for a longer description of the history of these codes, the conditions on which you may use these codes and which articles to cite.  The move to Julia is motivated by the desire to use /open source/ and /free/ (as in beer) software only while also ensuring that the tools are computationally efficient.  Octave has not kept up with developments in /just in time/ compilation and, although has some features not available in MATLAB, it is not a modern language.  Julia provides many of the capabilities of Octave while also being computationally efficient and providing many more modern features such as built-in parallelism and multi-dispatch.

This document has been written using [[http://orgmode.org/][org mode]] in the [[https://www.gnu.org/software/emacs/][Emacs]] text editor.  Org allows for /literate programming/ and uses /tangling/ to generate the actual source files for the code.  The code, tangled from this file, can be found here: call_distribution().

All code (either version) is copyright © {{{time(%Y)}}}, Eric S Fraga, all rights reserved.  Permission is given to use this code for evaluation purposes. The code is made available with no warranty or guarantee of any kind.  Use at own risk.  

Please let [[mailto:e.fraga@ucl.ac.uk?subject=The%20Strawberry%20code][the author know]] if you download the code.  Further, if either /Fresa/ or /Strawberry/ codes are used and this use leads to publications of any type, please do cite the publications listed in the first paragraph of the documentation for [[file:strawberry.org][Strawberry]].  Feedback, including bug reports, is most welcome.

In the following code, we assume column vectors for decision variables and objectives.  The convention on constraint violation is 1 meaning yes, i.e. infeasible solution, and 0 means no violation of the constraints.

** Upload to web site                                        :noexport:
#+name: upload
#+begin_src shell :results none :exports none :eval never-export
  scp -r fresa.org fresa.html Fresa.jl ltximg socrates.ucl.ac.uk:html.pub
#+end_src
** Code for creating a distribution                          :noexport:
#+name: distribution
#+begin_src shell :results output raw :exports results :eval never-export
  echo [[file:./Fresa.jl][Fresa.jl]]
#+end_src 
* Version information
Major version log:

- November 2016 :: first [[http://www.julialang.org/][Julia]] plant propagation algorithm implementation.
A list [[*Recent change history][summary of recent change history]] is given below.
* TODO [0/0] improvements or bugs                            :noexport:
* Fresa
:PROPERTIES:
:header-args: :tangle "Fresa.jl"
:END:
#+toc: headlines 2 local
The /Fresa/ method is a population based evolutionary algorithm which mimics the propagation used by plants.  Throughout the module, the population object is a 2d array.  Each column is a point in the search space consisting of =nx= decision variable values, =nz= objective function values and =g=, a single value indicating feasibility with =g≤0= feasible and =g>0= infeasible.

The objective function, =f(x)=, returns two variables: =z=, the vector of objective function values, and =g=, the indication of feasibility as discussed above.

** start of module
#+name: modulestart
#+begin_src julia
  module Fresa
  export solve
  version = "2017.09.05 11:24:10"
  function __init__()
      println("Fresa PPA $version")
  end
#+end_src
** COMMENT variables
These are variables that are global to the module.
#+name: variables
#+begin_src julia
  a = [0.0]                       # lower bounds
  b = [1.0]                       # upper bounds
#+end_src 
** fitness
The fitness function used depends on the number of objectives.  For single criterion problems, the fitness is the objective function values normalised and reversed so that the minimum, /i.e./ the best solution, has a fitness of close to 1 and the worst a fitness close to 0.  For multi-criteria problems, a Hadamard product of individual criteria rankings is used to create a fitness value [[[http://www.springer.com/gb/book/9783319299730][Fraga & Amusat, 2016]]].

This function uses a helper function, defined below, to assign a fitness to a vector of objective function values.
#+name: fitness
#+begin_src julia
  function fitness(pop,nx)
      k, l = size(pop)
      nz = k-nx-1
      indexfeasible = (1:l)[pop[k,:].<=0]
      indexinfeasible = (1:l)[pop[k,:].>0]
      # println("There are $(length(indexfeasible)) feasible entries and $(length(indexinfeasible)) infeasible")
      fit = zeros(l,1)
      factor = 1              # for placement in fitness interval (0,1)
      if length(indexfeasible) > 0
          feasible = view(pop,1:k,indexfeasible)
          feasiblefit = vectorfitness(nz, feasible[nx+1:nx+nz,:])
          if length(indexinfeasible) > 0
              feasiblefit = feasiblefit/2 + 0.5 # upper half of fitness internval
              factor = 2
          end
          fit[indexfeasible] = (feasiblefit+factor-1)/factor # upper half of fitness interval
      end
      if length(indexinfeasible) > 0
          # squeeze infeasible fitness values into (0,0.5) or (0,1) depending
          # on factor, i.e. whether there are any feasible solutions as well or not
          infeasible = view(pop,1:k,indexinfeasible)
          # use constraint violation for ranking
          fit[indexinfeasible] = vectorfitness(1, infeasible[nx+nz+1:nx+nz+1,:])/factor;
      end
      vec(fit)
  end
#+end_src 

#+name: vectorfitness
#+begin_src julia
  function vectorfitness(m,v)
      # println("VF: v=$v")
      # println("  : of size $(size(v))")
      if m == 1                   # single objective 
          l = length(v)
          s = sortperm(v[1,:])
          zmin = v[s[1]]
          zmax = v[s[l]]
          if l == 1 || abs(zmax-zmin) < eps()
              fit = 0.5*ones(l)
          else
              # avoid extreme 0,1 values
              fit = tanh.((zmax - v) / (zmax - zmin) - 0.5)+0.5
          end
      else                  # multi-objective
          m, l = size(v)
          rank = ones(m,l); #rank of each solution for each objective function 
          for i=1:m
              rank[i,sortperm(v[i,:])] = 1:l;
          end
          # hadamard product of ranks
          fitness = map(x->prod(x), rank[:,i] for i=1:l)
          # normalise and reverse meaning (1=best, 0=worst)
          if l == 1
              fit = [0.5]
          else
              # avoid extreme 0,1 values
              fit = tanh.(0.5 - fitness / maximum(fitness)) + 0.5
          end
      end
      # println("VF: fit=$fit")
      fit
  end

#+end_src 
** neighbour -- generate random point
A random solution is generated with a distance from the original point being inversely proportional, in a stochastic sense, to the fitness of the solution.  The new point is possibly adjusted to ensure it lies within the domain defined by the lower and upper bounds.  The final argument is the fitness vector with values between 0 and 1, 1 being the most fit and 0 the least fit.
#+name: neighbour
#+begin_src julia
  function neighbour(x,nx,a,b,f)
      xnew = x .+ (1-f) .* 2(rand(nx)-0.5) .* (b-a)
      xnew[xnew.<a] = a[xnew.<a];
      xnew[xnew.>b] = b[xnew.>b];
      return xnew
  end
#+end_src
** pareto -- set of non-dominated points
Select a set consisting of those solutions in a population that are not dominated.  This only applies to multi-objective optimisation; for a single criterion problem, the solution with minimum objective function value would be selected.  This function is used only for returning the set of non-dominated solutions at the end of the solution procedure for multi-objective problems.  It could be used for an alternative fitness function, /a la/ Srinivas /et al./ (N Srinivas & K Deb (1995), Evolutionary Computation *2*:221-248)
#+name: pareto
#+begin_src julia
  function pareto(pop,nx,nz)
      k, l = size(pop)
      z = pop[nx+1:nx+nz,:]
      p = pop[:,1]                # pareto front
      first = true
      for i in 1:l
          dominated = false
          for j in 1:l
              if i != j
                  if all(z[:,i] .>= z[:,j]) && any(z[:,i] .> z[:,j])
                      # println("$i dominated by $j")
                      # println("$(z[:,i]) >= $(z[:,j])")
                      dominated = true;
                      break;
                  end
              end
          end
          # println("member $(pop[:,i]) is dominated: $dominated")
          if !dominated
              if first
                  p[:,1] = pop[:,i]
                  first = false
              else
                  p = hcat(p,pop[:,i])
              end
          end
      end
      p
  end

#+end_src
** randompopulation -- for testing other methods
Create a random population of size ~n~ evaluated using ~f~.
#+name: randompopulation
#+begin_src julia
  function randompopulation(n,f,a,b)
      nx = length(b)
      x = a + rand(nx).*b
      z, g = f(x)
      k = length(x) + length(z) + 1;
      p = zeros(k,n);
      p[:,1] = [x;z;g]
      @sync @parallel for j in 2:n
          x = a + rand(nx).*b
          z, g = f(x)
          p[:,j] = [x;z;g]
      end
      p
  end
#+end_src 
** select -- choose a member of the population
Given a fitness, ~f~, choose two solutions randomly and select the one with the better fitness.  This is known as a /tournament/ selection procedure of size 2.  Other options are possible but not currently implemented.
#+name: select
#+begin_src julia
  function select(f)
      l = length(f)
      ind1 = rand(1:l)
      if ind1 == 0
          ind1 = 1
      end
      ind2 = rand(1:l)
      # println("Comparing $ind1 to $ind2")
      if f[ind1] > f[ind2]
          return ind1
      else
          return ind2
      end
  end
#+end_src 
** COMMENT set bounds -- for real valued decision vectors
Used to set some of the module global variables used by many of the functions in the module.  This could have been done in the main ~solve~ function but was taken out to make testing of small parts of the module easier.
#+name: setbounds
#+begin_src julia
  function setbounds(lower,upper)
      global a = lower;
      global b = upper;
      global n = length(lower);
      # println("Size of problem: $n")
  end
#+end_src
** solve -- use the PPA to solve the optimisation problem
The function expects the objective function, ~f~, an initial guess, ~x0~, and lower, ~a~, and upper, ~b~, bounds.  It returns the optimum, the objective function value(s) at this point, the constraint at that point and the whole population at the end.  The actual return values and data structures depends on the number of criteria:
- 1 :: returns best point, the objective function value, the constraint value and the full population;
- >1 :: returns the set of non-dominated points (as an array including objective function values and constraint value) and the full population.
#+name: solve
#+begin_src julia
  function solve(f,x0,a,b;
                 ngen=100, npop=10, output=5, nrmax=5, ns=100,
                 neighbourfn=neighbour)
      tstart = time()
      nx = length(a)
      z, g = f(x0)
      nz = length(z)
      println(": initial point, f($x0) = $z, with constraint $g")
      println(": there are $nz objective functions.")
      pop = reshape([x0;z;g],nx+nz+1,1) # should not be necessary
      for gen in 1:ngen
          fit = fitness(pop,nx)
          index = sortperm(fit)
          best = pop[:,index[length(fit)]]
          print(": $gen best is $(best[nx+1:nx+nz+1])\r")
          if gen%output == 0
              @printf("| %9d | %9.2f | ", gen, time()-tstart)
              j = nz>1 ? nx+1 : 1
              for i=j:nx+nz+1
                  @printf("%9g |", best[i])
              end
              println()
          end
          newpop = best
          k, l = size(pop)
          for i in 1:min(l,npop)
              s = select(fit)
              # println(": selection $i is $s")
              # println(": size of pop is $(size(pop))")
              selected = pop[:,s]
              newpop = hcat(newpop,selected)
              nr = ceil(fit[s]*nrmax*rand())
              if nr < 1
                  nr = 1
              end
              # println(": generating $nr runners")
              for r in 1:nr
                  x = neighbourfn(pop[1:nx,s],nx,a,b,fit[s])
                  z, g = f(x)
                  newpop = hcat(newpop,[x;z;g])
              end
          end
          pop = newpop;
      end
      fit = fitness(pop,nx)
      index = sortperm(fit)
      if nz == 1
          best = pop[:,index[length(fit)]]
          return best[1:nx], best[nx+1:nx+nz], best[nx+nz+1], pop
      else
          return pareto(pop,nx,nz), pop
      end
  end
#+end_src 
** module end
#+name: moduleend
#+begin_src julia
  end
#+end_src
* tests
The following are simple tests for either the Fresa optimiser or just individual functions in the module.  You can cut and paste these codes into your own editor and run them.
#+toc: headlines 2 local
** neighbour
#+name: testneighbour
#+begin_src julia :tangle testneighbour.jl
  using Fresa
  nx = 5
  a = -5*ones(nx,1)
  b = 5*ones(nx,1)
  x = a + (b-a) .* rand(nx)
  println("$x")
  for i in 1:10
      print("$i: ")
      n = Fresa.neighbour(x,nx,a,b,0.9)
      println("$n")
  end
#+end_src

** fitness test
This test uses a simple quadratic objective function to test out the fitness evaluation.
#+name: testfitness
#+begin_src julia :tangle testfitness.jl
  using Fresa
  nx = 2
  x0 = 0.5*ones(nx,1)
  a = zeros(nx,1)
  b = 10*ones(nx,1)
  f = x -> ((x[1]-3)^2+(x[2]-5)^2+8, 0)
  z, g = f(x0)
  pop = [x0;z;g]
  for i in 1:5
      x = Fresa.neighbour(x0,nx,a,b,0.5)
      z, g = f(x)
      pop = hcat(pop, [x;z;g])
      npop = size(pop)
      l = length(pop)
      println("Population size $npop with length $l")
  end
  z = pop[3,:]
  println("Objective function values: $z")
  fit = Fresa.fitness(pop)
  println("Fitness: $fit")
  for i in 1:5
      index = Fresa.select(fit)
      println("$i selected $index")
  end
#+end_src
** mixed integer nonlinear example
The MINLP example comes from: Tapio Westerlund & Joakim Westerlund, /GGPECP -- An algorithm for solving non-convex MINLP problems by cutting plane and transformation techniques/, Proceedings of ICHEAP-6, Pisa, June 2003.  It has one real variable and one integer variable.  The search region is non-convex, consisting of two disjoint domains.  The aim of this example is to test the use of a non-default /neighbour/ function.

#+name: testminlp
#+begin_src julia :tangle testminlp.jl
  using Fresa
  nx = 2;
  f = x -> (3x[2] - 5x[1],
            max(2x[2] + 3x[1] - 24,
                3x[1] - 2x[2] - 8,
                2x[2]^2 - 2*sqrt(x[2]) + 11x[2] + 8x[1] - 39 - 2*sqrt(x[1])*x[2]^2))
  a = [1.0; 1.0]
  b = [6.0; 6.0]
  function neighbour(x,nx,a,b,f)
      # first x is real, second is integer
      newx = x .+ (b-a).*(1-f) .* 2 .* (rand(nx)-0.5)
      newx[2] = round(newx[2])
      newx[newx.<a] = a[newx.<a]
      newx[newx.>b] = b[newx.>b]
      return newx
  end
  bestx, bestz, bestg, pop = Fresa.solve(f, [1.;1.], a, b; neighbourfn=neighbour)
  println("Population: $pop")
  println("Best: f($bestx) = $bestz, $bestg")
#+end_src 

** multi-objective test
#+name: testmultiobjective
#+begin_src julia :tangle testmultiobjective.jl
  using Fresa
  nx = 2
  a = zeros(nx,1)
  b = ones(nx,1)
  x = rand(nx,1)
  f = x -> ( [sin(x[1]-x[2]); cos(x[1]+x[2])], 0)
  pareto, population = Fresa.solve(f, x, a, b; npop=100)

  println("Pareto front:")
  println(pareto)

  using PyPlot
  PyPlot.plot(pareto[3,:], pareto[4,:], "ro")
  PyPlot.savefig("x.pdf")
#+end_src 
** multi-objective test with 3 objectives
#+name: testmultiobjective3
#+begin_src julia :tangle testmultiobjective3.jl
  using Fresa
  nx = 5
  a = zeros(nx,1)
  b = ones(nx,1)
  x = zeros(nx,1)
  f = x -> ([ sum((x-0.5).^2+1)
              sum(cos.(x))
              sum(sin.(x))],
            0)
  pareto, population = Fresa.solve(f, x, a, b; npop=100, ngen=1000, output=100)

  println("Pareto front:")
  println(pareto)

  using PyPlot
  PyPlot.plot3D(pareto[nx+1,:], pareto[nx+2,:], pareto[nx+3,:], "ro")
  PyPlot.savefig("x.pdf")
#+end_src 

** parallel test
Some code to play with the generation of a random population so as to learn how to parallelise a loop in Julia.
#+begin_src julia :tangle testparallel.jl
  using Fresa
  m = 10000;
  n = 1;
  a = zeros(n,1)
  b = π * ones(n,1)
  f = x -> ( sum(sin.(x/i) for i=1:10000), 0)
  @time p = Fresa.randompopulation(m,f,a,b)
#+end_src 
** pareto test
#+name: testpareto
#+begin_src julia :tangle testpareto.jl
  using Fresa
  nx = 2
  a = zeros(nx,1)
  b = ones(nx,1)
  x = rand(nx)
  f = x -> ( [sin(x[1]-x[2]); cos(x[1]+x[2])], 0)
  z, g = f(x)
  pop = [x; z; g]
  for i=1:9
      x = rand(nx)
      z, g = f(x)
      pop = hcat(pop,[x; z; g])
  end
  p = Fresa.pareto(pop,nx)
  println("Population is $pop")
  println("Pareto set is $p")
#+end_src 
** rosenbrock
#+name: testrosenbrock
#+begin_src julia :tangle testrosenbrock.jl
  using Fresa
  nx = 2
  x0 = 0.5*ones(nx,1)
  a = zeros(nx,1)
  b = 10*ones(nx,1)
  rosenbrock(x) = ((1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2, 0)
  # f = x -> ((x[1]-3)^2+(x[2]-5)^2+8, 0)
  bestx, bestz, bestg, pop = Fresa.solve(rosenbrock, x0, a, b)
  println("Population at end: $pop")
  println("Best solution is f($bestx)=$bestz with g=$bestg")
#+end_src
** simple objective function
This test uses a simple quadratic objective function, defined within.  All points are feasible within the domain defined by the lower and upper bounds.  All /Fresa/ settings are the defaults.
#+name: testsimple
#+begin_src julia :tangle testsimple.jl
  using Fresa
  nx = 2
  x0 = 0.5*ones(nx,1)
  a = zeros(nx,1)
  b = 10*ones(nx,1)
  f = x -> ((x[1]-3)^2+(x[2]-5)^2+8, 0)
  bestx, bestz, bestg, pop = Fresa.solve(f, x0, a, b)
  println("Population at end: $pop")
  println("Best solution is f($bestx)=$bestz with g=$bestg")
#+end_src 
* Recent change history
#+name: changehistoryshellblock
#+begin_src shell :exports results :results output
  hg log --template "{date|shortdate} {desc|firstline}\n" --limit 10 fresa.org
#+end_src
* settings                                                    :noexport:
** latex settings
#+begin_export latex
\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
      end,export,false,for,function,immutable,import,importall,if,in,%
      macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
      using,while},%
   sensitive=true,%
   alsoother={$},%
   morecomment=[l]\#,%
   morecomment=[n]{\#=}{=\#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]%

\lstset{%
    language         = Julia,
    basicstyle       = \ttfamily,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{magenta},
    commentstyle     = \color{ForestGreen},
    showstringspaces = false,
}
#+end_export
** org startup on file visit
#+name: startup
#+begin_src emacs-lisp :results none
  (setq-local htmlize-output-type 'inline-css)
#+end_src
** emacs local variables

# Local Variables:
# eval: (esf/execute-startup-block)
# time-stamp-line-limit: 1000
# time-stamp-format: "%04y.%02m.%02d %02H:%02M:%02S"
# time-stamp-active: t
# time-stamp-start: "version = \""
# time-stamp-end: "\""
# End:
