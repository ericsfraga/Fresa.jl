#+INCLUDE:   /home/ucecesf/hg/homepages/level-0.org
#+title: Fresa, a plant propagation algorithm
#+options: num:nil ^:nil toc:nil tex:imagemagick

| *Author*        | {{{author}}} ({{{email}}})                   |
| *Last revision* | {{{modification-time(%Y-%m-%d %H:%M:%S,t)}}} |

#+toc: headlines 1

* TODO bugs and new features [3/9]                            :noexport:
- [ ] Pareto set should not include infeasible points (unless all are infeasible?
- [ ] keep Pareto set as elite
- [X] current version requires =f= to return a vector for objective function value.  A single objective function should not require this so need to catch this case.
- [ ] consider splicing out the selected member from the population
- [ ] parallelise the evaluation of the new members of the population
- [ ] add counters to be able to display number of function evaluations etc.
- [ ] use constraint information in fitness calculations
- [X] allow for user specified /neighbour/ function
- [X] implement MINLP example
* Overview and introduction
/Fresa/ is an implementation of a /plant propagation algorithm/ in [[http://www.julialang.org/][Julia]] programming language.  Our original version was called [[file:strawberry.org][Strawberry]], written in Octave (and usable in MATLAB).  Please see the [[file:strawberry.org][documentation]] of Strawberry for a longer description of the history of these codes, the conditions on which you may use these codes and which articles to cite.  The move to Julia is motivated by the desire to use /open source/ and /free/ (as in beer) software only while also ensuring that the tools are computationally efficient.  Octave has not kept up with developments in /just in time/ compilation and, although has some features not available in MATLAB, it is not a modern language.  Julia provides many of the capabilities of Octave while also being computationally efficient and providing many more modern features such as built-in parallelism and multi-dispatch.

This document has been written using [[http://orgmode.org/][org mode]] in the [[https://www.gnu.org/software/emacs/][Emacs]] text editor.  Org allows for /literate programming/ and uses /tangling/ to generate the actual source files for the code.  The code, tangled from this file, can be found here: call_distribution().  To use this code, you should probably add this to your =~/.juliarc.jl= file (for Linux; for MS Windows, check the [[http://www.julialang.org/][Julia]] documentation):
#+begin_example
push!(LOAD_PATH,"/directory/where/Fresa/was/saved")
#+end_example

All code (either version) is copyright © {{{time(%Y)}}}, Eric S Fraga, all rights reserved.  Permission is given to use this code for evaluation purposes. The code is made available with no warranty or guarantee of any kind.  Use at own risk.  

Please let [[mailto:e.fraga@ucl.ac.uk?subject=The%20Strawberry%20code][the author know]] if you download the code.  Further, if either /Fresa/ or /Strawberry/ codes are used and this use leads to publications of any type, please do cite the publications listed in the first paragraph of the documentation for [[file:strawberry.org][Strawberry]].  Feedback, including bug reports, is most welcome.

** Upload to web site                                        :noexport:
#+name: upload
#+begin_src shell :results none :exports none :eval never-export
  scp -r fresa.org fresa.html Fresa.jl ltximg socrates.ucl.ac.uk:html.pub
#+end_src
** Code for creating a distribution                          :noexport:
#+name: distribution
#+begin_src shell :results output raw :exports results
  echo [[file:./Fresa.jl][Fresa.jl]]
#+end_src 
** Version information
Major version log:

- September 2017 :: moved to an object representation for points in the search space.
- November 2016 :: first [[http://www.julialang.org/][Julia]] plant propagation algorithm implementation.
A list [[*Recent change history][summary of recent change history]] is given below.
* TODO [0/0] improvements or bugs                            :noexport:
* Fresa – The code and documentation
:PROPERTIES:
:header-args: :tangle "Fresa.jl"
:END:
#+toc: headlines 2 local
The /Fresa/ method is a population based evolutionary algorithm which mimics the propagation used by plants.  Throughout the module, the population object is an array of =Point= objects.  Each point is a point in a search space, the objective function values for this point and a feasibility indication with =g≤0= feasible and =g>0= infeasible.  See the documentation [[*solve -- use the PPA to solve the optimisation problem][for the =solve= method below]] for more details on the data structures used and expected.
** start of module
#+name: modulestart
#+begin_src julia
  module Fresa
  export solve
  version = "2017.09.07 10:02:18"
  function __init__()
      println("Fresa PPA $version")
  end
#+end_src
** types
Fresa uses one type, =Point=, which is a point in the search space.  It includes the variable =x=, of indeterminate type to allow for a wide range of applications (e.g. integer versus real values), =z=, the value of the objective function, and =g=, the constraint violation (feasible with ≤0 and infeasible otherwise).
#+name: types
#+begin_src julia
  type Point
      x :: Any                    # decision point
      z :: Array{Float64}         # objective function values
      g :: Float64                # constraint violation
      function Point(x, f)
          (z, g) = f(x)
          if typeof(z) == Array{Float64} || typeof(z) == Array{Float64,1}
              new(x,z,g)
          elseif typeof(z) == Float64
              new(x,[z],g)
          else
              error("Objective function values should be Float64 values, not $(typeof(z))")
          end
      end
  end
#+end_src 
** COMMENT variables
These are variables that are global to the module.
#+name: variables
#+begin_src julia
  a = [0.0]                       # lower bounds
  b = [1.0]                       # upper bounds
#+end_src 
** fitness
The fitness function used depends on the number of objectives.  For single criterion problems, the fitness is the objective function values normalised and reversed so that the minimum, /i.e./ the best solution, has a fitness of close to 1 and the worst a fitness close to 0.  For multi-criteria problems, a Hadamard product of individual criteria rankings is used to create a fitness value [[[http://www.springer.com/gb/book/9783319299730][Fraga & Amusat, 2016]]].

This function uses a helper function, defined below, to assign a fitness to a vector of objective function values.
#+name: fitness
#+begin_src julia
  function fitness(pop)
      l = length(pop)
      indexfeasible = (1:l)[map(p->p.g,pop) .<= 0]
      indexinfeasible = (1:l)[map(p->p.g,pop) .> 0]
      # println("There are $(length(indexfeasible)) feasible entries and $(length(indexinfeasible)) infeasible")
      fit = zeros(l)
      factor = 1              # for placement in fitness interval (0,1)
      if length(indexfeasible) > 0
          feasible = view(pop,indexfeasible)
          # use objective function value(s) for ranking
          feasiblefit = vectorfitness(map(p->p.z,feasible))
          if length(indexinfeasible) > 0
              feasiblefit = feasiblefit/2 + 0.5 # upper half of fitness interval
              factor = 2                        # have both feasible & infeasible
          end
          fit[indexfeasible] = (feasiblefit+factor-1)/factor
      end
      if length(indexinfeasible) > 0
          # squeeze infeasible fitness values into (0,0.5) or (0,1) depending
          # on factor, i.e. whether there are any feasible solutions as well or not
          infeasible = view(pop,indexinfeasible)
          # use constraint violation for ranking as objective function values
          # may not make any sense given that points are infeasible
          fit[indexinfeasible] = vectorfitness(map(p->p.g, infeasible))/factor;
      end
      fit
  end
#+end_src 

#+name: vectorfitness
#+begin_src julia
  function vectorfitness(v)
      # determine number of objectives (or pseudo-objectives) to consider in
      # ranking
      l = length(v)
      if l == 1
          # no point in doing much as there is only one solution
          fit = [0.5]
      else
          m = length(v[1])
          # println("VF: v=$v")
          # println("  : of size $(size(v))")
          if m == 1                   # single objective 
              v = [v[i][1] for i=1:l]
              s = sortperm(v)
              zmin = v[s[1]]
              zmax = v[s[l]]
              if abs(zmax-zmin) < eps()
                  fit = 0.5*ones(l)
              else
                  # avoid extreme 0,1 values
                  fit = tanh.((zmax - v) / (zmax - zmin) - 0.5)+0.5
              end
          else                  # multi-objective
              rank = ones(m,l); #rank of each solution for each objective function 
              for i=1:m
                  rank[i,sortperm([v[j][i] for j=1:l])] = 1:l;
              end
              # hadamard product of ranks
              fitness = map(x->prod(x), rank[:,i] for i=1:l)
              # normalise and reverse meaning (1=best, 0=worst) while avoiding
              # extreme 0,1 values using the hyperbolic tangent
              fit = tanh.(0.5 - fitness / maximum(fitness)) + 0.5
          end
      end
      # println("VF: fit=$fit")
      fit
  end

#+end_src 
** neighbour -- generate random point
A random solution is generated with a distance from the original point being inversely proportional, in a stochastic sense, to the fitness of the solution.  The new point is possibly adjusted to ensure it lies within the domain defined by the lower and upper bounds.  The final argument is the fitness vector with values between 0 and 1, 1 being the most fit and 0 the least fit.

This is the default implementation which assumes that the points in the search space are described by a real valued vector.
#+name: neighbour
#+begin_src julia
  function neighbour(x,a,b,f)
      xnew = x .+ (1-f) .* 2(rand(length(x))-0.5) .* (b-a)
      xnew[xnew.<a] = a[xnew.<a];
      xnew[xnew.>b] = b[xnew.>b];
      return xnew
  end
#+end_src
** pareto -- set of non-dominated points
Select a set consisting of those solutions in a population that are not dominated.  This only applies to multi-objective optimisation; for a single criterion problem, the solution with minimum objective function value would be selected.  This function is used only for returning the set of non-dominated solutions at the end of the solution procedure for multi-objective problems.  It could be used for an alternative fitness function, /a la/ Srinivas /et al./ (N Srinivas & K Deb (1995), Evolutionary Computation *2*:221-248)
#+name: pareto
#+begin_src julia
  function pareto(pop)
      l = length(pop)
      indexfeasible = (1:l)[map(p->p.g,pop) .<= 0]
      indexinfeasible = (1:l)[map(p->p.g,pop) .> 0]
      if length(indexfeasible) > 0
          subset = view(pop,indexfeasible)
      else
          println(": Fresa.pareto warning: no feasible solutions.  Pareto set meaningless?")
          subset = pop
      end
      l = length(subset)
      z = map(p->p.z, subset)
      p = Point[]                 # pareto front array
      for i in 1:l
          dominated = false
          for j in 1:l
              if i != j
                  if all(z[i] .>= z[j]) && any(z[i] .> z[j])
                      # println("$i dominated by $j")
                      # println("$(z[:,i]) >= $(z[:,j])")
                      dominated = true;
                      break;
                  end
              end
          end
          # println("member $(pop[i]) is dominated: $dominated")
          if !dominated
              push!(p,subset[i])
          end
      end
      p
  end

#+end_src
** prune - control population diversity
Due to the stochastic nature of the method and also the likely duplication of points when elitism is used, there is a need to prune the population.  We wish to remove members that have objective function values that are too close to each other.  The main difficulty is the definition of /too close/.  We use a tolerance based on the range of values present in the population.
#+name: prune
#+begin_src julia
  function prune(pop::Array{Point})
      z = map(p->p.z, pop)
      # println("typeof(z)=$(typeof(z))")
      l = length(z)
      # println("typeof(z[1])=$(typeof(z[1]))")
      n = length(z[1])
      zmin = zeros(n)
      zmax = zeros(n)
      for i=1:n
          row = [z[j][i] for j=1:l]
          zmin[i] = minimum(row)
          zmax[i] = maximum(row)
          if zmax[i] - zmin[i] < 100*eps()
              zmax[i] = zmin[i]+100*eps()
          end
      end
      pruned = [pop[1]]
      for i=2:l
          similar = false
          for j=1:length(pruned)
              if norm((z[i]-pruned[j].z)./(zmax-zmin)) < 100*eps()
                  similar = true;
                  break;
              end
          end
          if !similar
              push!(pruned,pop[i])
          end
      end
      pruned
  end
#+end_src 
** COMMENT randompopulation -- for testing other methods
Create a random population of size ~n~ evaluated using ~f~.
#+name: randompopulation
#+begin_src julia
  function randompopulation(n,f,a,b)
      p = Point[]                 # population object
      @sync @parallel for j in 1:n
          push!(p, Point(randompoint(a,b), f))
      end
      p
  end
#+end_src 
By default, the following method generates a random point within the search domain.  This does not attempt to find a feasible point, simply one within the box defined by lower, =a=, and upper, =b=, bounds.  
#+name: randompoint
#+begin_src julia
  function randompoint(a,b)
      x = a + rand(length(a)).*b
  end
#+end_src 
** select -- choose a member of the population
Given a fitness, ~f~, choose two solutions randomly and select the one with the better fitness.  This is known as a /tournament/ selection procedure of size 2.  Other options are possible but not currently implemented.
#+name: select
#+begin_src julia
  function select(f)
      l = length(f)
      ind1 = rand(1:l)
      if ind1 == 0
          ind1 = 1
      end
      ind2 = rand(1:l)
      # println("Comparing $ind1 to $ind2")
      if f[ind1] > f[ind2]
          return ind1
      else
          return ind2
      end
  end
#+end_src 
** COMMENT set bounds -- for real valued decision vectors
Used to set some of the module global variables used by many of the functions in the module.  This could have been done in the main ~solve~ function but was taken out to make testing of small parts of the module easier.
#+name: setbounds
#+begin_src julia
  function setbounds(lower,upper)
      global a = lower;
      global b = upper;
      global n = length(lower);
      # println("Size of problem: $n")
  end
#+end_src
** solve -- use the PPA to solve the optimisation problem
The function expects the objective function, ~f~, an initial guess, ~x0~, and lower, ~a~, and upper, ~b~, bounds.  It returns the optimum, the objective function value(s) at this point, the constraint at that point and the whole population at the end.  The actual return values and data structures depends on the number of criteria:
- 1 :: returns best point, the objective function value, the constraint value and the full population;
- >1 :: returns the set of non-dominated points (as an array including objective function values and constraint value) and the full population.
     
The objective function, =f=, should return two results: =z=, the objective function value(s) which must be of type =Float64=, single or array, and =g=, the constraint violation.  If =g≤0=, the point is feasible; any value =g>0= means an infeasible point.  The value of =g= for infeasible points will be used to rank the fitness of the infeasible solution, with lower values being fitter.

=x0= is the initial guess and can be of any type.  =a= and =b= are lower and upper bounds and should be of types consistent with each other and =x0=.  Note that the =neighbourfn= must be specified if the decision points are not arrays of =Float64= or if a different definition of neighbouring points is desired.  The calling sequence for =neighbourfn= is =(x,a,b,fitness)= for some =x=.
#+name: solve
#+begin_src julia
  function solve(f, x0, a, b;     # required arguments
                 elite = true,    # elitism by default
                 neighbourfn = neighbour, # neighbour function to use
                 ngen = 100,      # number of generations
                 npop = 10,       # population size
                 nrmax = 5,       # number of runners maximum
                 ns = 100,        # number of stable solutions for stopping
                 output = 5)      # how often to output information
      tstart = time()
      p0 = Point(x0,f)            # initial point
      nf = 1                      # number of function evaluations
      nz = length(p0.z)           # number of criteria
      pop = [p0];                 # create/initialise the population object
      println(": initial population, $pop")
      @printf("| %9s | %9s | %9s | %9s |", "gen", "npop",
              elite ? "np" : "nf", "t (s)")
      for i in 1:nz
          @printf(" z%-8d |", i)
      end
      @printf("\n|-\n")
      for gen in 1:ngen
          fit = fitness(pop)
          index = sortperm(fit)
          best = pop[index[end]]
          # if elitism is used
          if elite
              if nz > 1
                  newpop = pareto(pop)
              else
                  newpop = [best]
              end
          else
              newpop = Array{Float64,1}
          end
          print(": $gen np=$(length(newpop)) with most fit z=$(best.z)           \r")
          if gen%output == 0
              @printf("| %9d | %9d | %9d | %9.2f |", gen, length(fit),
                      elite ? length(newpop) : nf, time()-tstart)
              for i = 1:length(best.z)
                  @printf(" %9g |", best.z[i])
              end
              println()
          end
          l = length(pop)
          for i in 1:min(l,npop)
              s = select(fit)
              # println(": selection $i is $s")
              # println(": size of pop is $(size(pop))")
              selected = pop[s]
              # push!(newpop, selected)
              nr = ceil(fit[s]*nrmax*rand())
              if nr < 1
                  nr = 1
              end
              # println(": generating $nr runners")
              for r in 1:nr
                  x = neighbourfn(pop[s].x,a,b,fit[s])
                  push!(newpop, Point(x, f))
                  nf += 1
              end
          end
          pop = prune(newpop);
      end
      fit = fitness(pop)
      index = sortperm(fit)
      if nz == 1
          best = pop[index[end]]
          return best.x, best.z, best.g, pop
      else
          return pareto(pop), pop
      end
  end
#+end_src 
** module end
#+name: moduleend
#+begin_src julia
  end
#+end_src
* Tests
The following are simple tests for either the Fresa optimiser or just individual functions in the module.  You can cut and paste these codes into your own editor and run them.
#+toc: headlines 2 local
** COMMENT neighbour
#+name: testneighbour
#+begin_src julia :tangle testneighbour.jl
  using Fresa
  nx = 5
  a = -5*ones(nx,1)
  b = 5*ones(nx,1)
  x = a + (b-a) .* rand(nx)
  println("$x")
  for i in 1:10
      print("$i: ")
      n = Fresa.neighbour(x,nx,a,b,0.9)
      println("$n")
  end
#+end_src

** COMMENT fitness test
This test uses a simple quadratic objective function to test out the fitness evaluation.
#+name: testfitness
#+begin_src julia :tangle testfitness.jl
  using Fresa
  nx = 2
  x0 = 0.5*ones(nx,1)
  a = zeros(nx,1)
  b = 10*ones(nx,1)
  f = x -> ((x[1]-3)^2+(x[2]-5)^2+8, 0)
  z, g = f(x0)
  pop = [x0;z;g]
  for i in 1:5
      x = Fresa.neighbour(x0,nx,a,b,0.5)
      z, g = f(x)
      pop = hcat(pop, [x;z;g])
      npop = size(pop)
      l = length(pop)
      println("Population size $npop with length $l")
  end
  z = pop[3,:]
  println("Objective function values: $z")
  fit = Fresa.fitness(pop)
  println("Fitness: $fit")
  for i in 1:5
      index = Fresa.select(fit)
      println("$i selected $index")
  end
#+end_src
** mixed integer nonlinear example
The MINLP example comes from: Tapio Westerlund & Joakim Westerlund, /GGPECP -- An algorithm for solving non-convex MINLP problems by cutting plane and transformation techniques/, Proceedings of ICHEAP-6, Pisa, June 2003.  It has one real variable and one integer variable.  The search region is non-convex, consisting of two disjoint domains.  The aim of this example is to test the use of a non-default /neighbour/ function.

#+name: testminlp
#+begin_src julia :tangle testminlp.jl
  using Fresa
  nx = 2;
  f = x -> (3x[2] - 5x[1],
            max(2x[2] + 3x[1] - 24,
                3x[1] - 2x[2] - 8,
                2x[2]^2 - 2*sqrt(x[2]) + 11x[2] + 8x[1] - 39 - 2*sqrt(x[1])*x[2]^2))
  a = [1.0; 1.0]
  b = [6.0; 6.0]
  function neighbour(x,nx,a,b,f)
      # first x is real, second is integer
      newx = x .+ (b-a).*(1-f) .* 2 .* (rand(nx)-0.5)
      newx[2] = round(newx[2])
      newx[newx.<a] = a[newx.<a]
      newx[newx.>b] = b[newx.>b]
      return newx
  end
  bestx, bestz, bestg, pop = Fresa.solve(f, [1.;1.], a, b; neighbourfn=neighbour)
  println("Population: $pop")
  println("Best: f($bestx) = $bestz, $bestg")
#+end_src 

** multi-objective test
#+name: testmultiobjective
#+begin_src julia :tangle testmultiobjective.jl
  using Fresa
  nx = 2
  a = zeros(nx,1)
  b = ones(nx,1)
  x = rand(nx,1)
  f = x -> ( [sin(x[1]-x[2]); cos(x[1]+x[2])], 0)
  pareto, population = Fresa.solve(f, x, a, b; npop=100)

  println("Pareto front:")
  println(pareto)

  using PyPlot
  z = [pareto[i].z for i in 1:length(pareto)];
  PyPlot.plot([z[i][1] for i=1:length(z)],
              [z[i][2] for i=1:length(z)],
              "ro")
  PyPlot.savefig("x.pdf")
#+end_src 
** multi-objective test with 3 objectives
#+name: testmultiobjective3
#+begin_src julia :tangle testmultiobjective3.jl
  using Fresa
  nx = 5
  a = zeros(nx,1)
  b = ones(nx,1)
  x = zeros(nx,1)
  f = x -> ([ sum((x-0.5).^2+1)
              sum(cos.(x))
              sum(sin.(x))],
            0)
  pareto, population = Fresa.solve(f, x, a, b; npop=100, ngen=1000, output=100)

  println("Pareto front:")
  println(pareto)

  using PyPlot
  z = [pareto[i].z for i in 1:length(pareto)];
  PyPlot.plot3D([z[i][1] for i=1:length(z)],
                [z[i][2] for i=1:length(z)],
                [z[i][3] for i=1:length(z)],
                "ro")
  PyPlot.savefig("x3.pdf")
#+end_src 

** COMMENT parallel test
Some code to play with the generation of a random population so as to learn how to parallelise a loop in Julia.
#+begin_src julia :tangle testparallel.jl
  using Fresa
  m = 10000;
  n = 1;
  a = zeros(n,1)
  b = π * ones(n,1)
  f = x -> ( sum(sin.(x/i) for i=1:10000), 0)
  @time p = Fresa.randompopulation(m,f,a,b)
#+end_src 
** COMMENT pareto test
#+name: testpareto
#+begin_src julia :tangle testpareto.jl
  using Fresa
  nx = 2
  a = zeros(nx,1)
  b = ones(nx,1)
  x = rand(nx)
  f = x -> ( [sin(x[1]-x[2]); cos(x[1]+x[2])], 0)
  z, g = f(x)
  pop = [x; z; g]
  for i=1:9
      x = rand(nx)
      z, g = f(x)
      pop = hcat(pop,[x; z; g])
  end
  p = Fresa.pareto(pop,nx)
  println("Population is $pop")
  println("Pareto set is $p")
#+end_src 
** rosenbrock
#+name: testrosenbrock
#+begin_src julia :tangle testrosenbrock.jl
  using Fresa
  nx = 2
  x0 = 0.5*ones(nx,1)
  a = zeros(nx,1)
  b = 10*ones(nx,1)
  rosenbrock(x) = ([(1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2], 0)
  # f = x -> ((x[1]-3)^2+(x[2]-5)^2+8, 0)
  bestx, bestz, bestg, pop = Fresa.solve(rosenbrock, x0, a, b)
  println("Population at end: $pop")
  println("Best solution is f($bestx)=$bestz with g=$bestg")
#+end_src
** simple objective function
This test uses a simple quadratic objective function, defined within.  All points are feasible within the domain defined by the lower and upper bounds.  All /Fresa/ settings are the defaults.
#+name: testsimple
#+begin_src julia :tangle testsimple.jl
  using Fresa
  nx = 2
  x0 = 0.5*ones(nx)
  a = zeros(nx)
  b = 10*ones(nx)
  f = x -> ((x[1]-3)^2+(x[2]-5)^2+8, 0)
  bestx, bestz, bestg, pop = Fresa.solve(f, x0, a, b)
  println("Population at end: $pop")
  println("Best solution is f($bestx)=$bestz with g=$bestg")
#+end_src 
* Recent change history
#+name: changehistoryshellblock
#+begin_src shell :exports results :results output
  hg log --template "{date|shortdate} {desc|firstline}\n" --limit 10 fresa.org
#+end_src
* settings                                                    :noexport:
** latex settings
#+begin_export latex
\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
      end,export,false,for,function,immutable,import,importall,if,in,%
      macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
      using,while},%
   sensitive=true,%
   alsoother={$},%
   morecomment=[l]\#,%
   morecomment=[n]{\#=}{=\#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]%

\lstset{%
    language         = Julia,
    basicstyle       = \ttfamily,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{magenta},
    commentstyle     = \color{ForestGreen},
    showstringspaces = false,
}
#+end_export
** org startup on file visit
#+name: startup
#+begin_src emacs-lisp :results none
  (setq-local htmlize-output-type 'inline-css)
#+end_src
** emacs local variables

# Local Variables:
# eval: (esf/execute-startup-block)
# time-stamp-line-limit: 1000
# time-stamp-format: "%04y.%02m.%02d %02H:%02M:%02S"
# time-stamp-active: t
# time-stamp-start: "version = \""
# time-stamp-end: "\""
# End:
